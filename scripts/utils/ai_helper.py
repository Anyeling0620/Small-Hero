"""
AI æ¨¡å‹è¾…åŠ©å·¥å…·
æ”¯æŒ Gemini å’Œ DeepSeek è‡ªåŠ¨åˆ‡æ¢ï¼Œå¸¦é‡è¯•æœºåˆ¶
"""
import os
import time
import json
from typing import Optional, Dict, Any
import google.generativeai as genai

# é…ç½® API å¯†é’¥
GEMINI_API_KEY = os.getenv('GEMINI_API_KEY')
DEEPSEEK_API_KEY = os.getenv('DEEPSEEK_API_KEY')

class AIModelHelper:
    """AI æ¨¡å‹è¾…åŠ©ç±»ï¼Œæ”¯æŒä¸»å¤‡åˆ‡æ¢å’Œé‡è¯•"""
    
    def __init__(self, config: Dict[str, Any]):
        """
        åˆå§‹åŒ– AI æ¨¡å‹è¾…åŠ©ç±»
        
        Args:
            config: æ¨¡å‹é…ç½®ï¼ŒåŒ…å« primary å’Œ fallback
        """
        self.config = config
        self.primary_model = config.get('primary', {})
        self.fallback_model = config.get('fallback', {})
        self.retry_attempts = config.get('retryAttempts', 3)
        self.retry_delay = config.get('retryDelay', 5000) / 1000  # è½¬æ¢ä¸ºç§’
        
        # é…ç½® Gemini
        if GEMINI_API_KEY:
            genai.configure(api_key=GEMINI_API_KEY)
    
    def generate_content(self, prompt: str) -> Optional[str]:
        """
        ç”Ÿæˆå†…å®¹ï¼Œè‡ªåŠ¨é‡è¯•å’Œå¤‡ç”¨æ¨¡å‹åˆ‡æ¢
        
        Args:
            prompt: æç¤ºè¯
            
        Returns:
            ç”Ÿæˆçš„å†…å®¹ï¼Œå¤±è´¥è¿”å› None
        """
        # é¦–å…ˆå°è¯•ä¸»æ¨¡å‹
        result = self._try_model(self.primary_model, prompt, "ä¸»æ¨¡å‹")
        if result:
            return result
        
        # ä¸»æ¨¡å‹å¤±è´¥ï¼Œå°è¯•å¤‡ç”¨æ¨¡å‹
        print(f"âš ï¸  ä¸»æ¨¡å‹å¤±è´¥ï¼Œåˆ‡æ¢åˆ°å¤‡ç”¨æ¨¡å‹...")
        result = self._try_model(self.fallback_model, prompt, "å¤‡ç”¨æ¨¡å‹")
        if result:
            return result
        
        print(f"âŒ æ‰€æœ‰æ¨¡å‹å‡å¤±è´¥ï¼")
        return None
    
    def _try_model(self, model_config: Dict, prompt: str, model_name: str) -> Optional[str]:
        """
        å°è¯•ä½¿ç”¨æŒ‡å®šæ¨¡å‹ç”Ÿæˆå†…å®¹ï¼Œå¸¦é‡è¯•æœºåˆ¶
        
        Args:
            model_config: æ¨¡å‹é…ç½®
            prompt: æç¤ºè¯
            model_name: æ¨¡å‹åç§°ï¼ˆç”¨äºæ—¥å¿—ï¼‰
            
        Returns:
            ç”Ÿæˆçš„å†…å®¹ï¼Œå¤±è´¥è¿”å› None
        """
        model_type = model_config.get('model', '')
        
        for attempt in range(1, self.retry_attempts + 1):
            try:
                print(f"ğŸ¤– å°è¯•ä½¿ç”¨ {model_name} ({model_type})ï¼Œç¬¬ {attempt}/{self.retry_attempts} æ¬¡...")
                
                # Gemini æ¨¡å‹
                if 'gemini' in model_type.lower():
                    result = self._call_gemini(model_config, prompt)
                    if result:
                        print(f"âœ… {model_name} æˆåŠŸç”Ÿæˆå†…å®¹")
                        return result
                
                # DeepSeek æ¨¡å‹
                elif 'deepseek' in model_type.lower():
                    result = self._call_deepseek(model_config, prompt)
                    if result:
                        print(f"âœ… {model_name} æˆåŠŸç”Ÿæˆå†…å®¹")
                        return result
                
                else:
                    print(f"âŒ ä¸æ”¯æŒçš„æ¨¡å‹ç±»å‹: {model_type}")
                    return None
                    
            except Exception as e:
                print(f"âŒ {model_name} ç¬¬ {attempt} æ¬¡å°è¯•å¤±è´¥: {e}")
                
                if attempt < self.retry_attempts:
                    print(f"â³ ç­‰å¾… {self.retry_delay} ç§’åé‡è¯•...")
                    time.sleep(self.retry_delay)
        
        return None
    
    def _call_gemini(self, config: Dict, prompt: str) -> Optional[str]:
        """è°ƒç”¨ Gemini API"""
        model_name = config.get('model', 'gemini-2.5-flash-latest')
        temperature = config.get('temperature', 0.7)
        max_tokens = config.get('maxTokens', 8000)
        
        model = genai.GenerativeModel(
            model_name=model_name,
            generation_config=genai.GenerationConfig(
                temperature=temperature,
                max_output_tokens=max_tokens,
            )
        )
        
        response = model.generate_content(prompt)
        return response.text
    
    def _call_deepseek(self, config: Dict, prompt: str) -> Optional[str]:
        """è°ƒç”¨ DeepSeek API"""
        import requests
        
        model_name = config.get('model', 'deepseek-chat')
        base_url = config.get('baseUrl', 'https://api.deepseek.com/v1')
        temperature = config.get('temperature', 0.7)
        max_tokens = config.get('maxTokens', 8000)
        
        if not DEEPSEEK_API_KEY:
            raise Exception("DEEPSEEK_API_KEY æœªé…ç½®")
        
        headers = {
            'Authorization': f'Bearer {DEEPSEEK_API_KEY}',
            'Content-Type': 'application/json'
        }
        
        data = {
            'model': model_name,
            'messages': [
                {'role': 'user', 'content': prompt}
            ],
            'temperature': temperature,
            'max_tokens': max_tokens
        }
        
        response = requests.post(
            f"{base_url}/chat/completions",
            headers=headers,
            json=data,
            timeout=60
        )
        
        response.raise_for_status()
        result = response.json()
        
        return result['choices'][0]['message']['content']


def create_ai_helper(role: str) -> AIModelHelper:
    """
    æ ¹æ®è§’è‰²åˆ›å»º AI è¾…åŠ©ç±»
    
    Args:
        role: è§’è‰²åç§° (architect/backendDev/frontendDev/qaTester)
        
    Returns:
        AIModelHelper å®ä¾‹
    """
    # è¯»å–é…ç½®
    config_path = 'ai-orchestrator/project-config.json'
    with open(config_path, 'r', encoding='utf-8') as f:
        project_config = json.load(f)
    
    ai_config = project_config.get('aiModelConfig', {}).get(role, {})
    
    return AIModelHelper(ai_config)


if __name__ == '__main__':
    # æµ‹è¯•
    helper = create_ai_helper('architect')
    
    test_prompt = "è¯·ç®€å•ä»‹ç»ä¸€ä¸‹å°å°å‹‡è€…è¿™æ¬¾æ¸¸æˆã€‚"
    result = helper.generate_content(test_prompt)
    
    if result:
        print("\nç”Ÿæˆç»“æœ:")
        print(result)
    else:
        print("\nç”Ÿæˆå¤±è´¥ï¼")
